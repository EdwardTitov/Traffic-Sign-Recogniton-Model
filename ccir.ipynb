{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119c3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\etito\\miniconda3\\envs\\tf-env\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.3.1) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing neccessary libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import deeplake as dl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04cd6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/gtsrb-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/gtsrb-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/gtsrb-test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/gtsrb-test loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://activeloop/gtsrb-train', read_only=True, tensors=['images', 'boxes', 'labels', 'shapes', 'colors'])\n",
      "\n",
      " tensor      htype               shape              dtype  compression\n",
      " -------    -------             -------            -------  ------- \n",
      " images      image     (39209, 25:225, 25:243, 3)   uint8    jpeg   \n",
      "  boxes      bbox            (39209, 1, 4)         float32   None   \n",
      " labels   class_label          (39209, 1)          uint32    None   \n",
      " shapes   class_label          (39209, 1)          uint32    None   \n",
      " colors   class_label          (39209, 1)          uint32    None   \n",
      "None\n",
      "Image Shape: (26, 26, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading in Datasets\n",
    "train_ds = dl.load('hub://activeloop/gtsrb-train')\n",
    "test_ds = dl.load('hub://activeloop/gtsrb-test')\n",
    "print(train_ds.summary())\n",
    "train_shape = train_ds.images[0].shape\n",
    "print(f\"Image Shape: {train_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf61f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing Images\n",
    "def resize_images(images):\n",
    "    resized = tf.image.resize(images, (26, 26)).numpy()\n",
    "    normalized = resized / 255.0\n",
    "    return normalized\n",
    "train_images, test_images = train_ds.images.numpy(aslist=True), test_ds.images.numpy(aslist=True)\n",
    "train_labels, test_labels = train_ds.labels.numpy().squeeze(), test_ds.labels.numpy().squeeze()\n",
    "\n",
    "train_images_resized = np.array([resize_images(img) for img in train_images])\n",
    "test_images_resized = np.array([resize_images(img) for img in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44573c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7394 - loss: 1.0576\n",
      "Epoch 2/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9628 - loss: 0.1822\n",
      "Epoch 3/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9837 - loss: 0.0813\n",
      "Epoch 4/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9914 - loss: 0.0461\n",
      "Epoch 5/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9949 - loss: 0.0290\n",
      "Epoch 6/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9970 - loss: 0.0199\n",
      "Epoch 7/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9983 - loss: 0.0132\n",
      "Epoch 8/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.0100\n",
      "Epoch 9/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9995 - loss: 0.0071\n",
      "Epoch 10/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9995 - loss: 0.0051\n",
      "Epoch 11/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 0.0039\n",
      "Epoch 12/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9998 - loss: 0.0032\n",
      "Epoch 13/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9999 - loss: 0.0024\n",
      "Epoch 14/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9999 - loss: 0.0023\n",
      "Epoch 15/15\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# Create and Train Model\n",
    "def create_train_model(images, labels):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(26, 26, 3)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(43, activation='softmax')\n",
    "    ])\n",
    "    lr_scheduler = keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=10000,\n",
    "        alpha=0.0)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_scheduler),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(images, labels, epochs=15, batch_size=128)\n",
    "    return model\n",
    "traffic_sign_model = create_train_model(train_images_resized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ac97e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.2861\n",
      "Loss: 28.61 Accuracy: 93.76\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model on Accuracy and Loss\n",
    "def evaluate_model(model, images, labels):\n",
    "    loss, accuracy = model.evaluate(images, labels)\n",
    "    loss, accuracy = np.round(loss * 100, 2), np.round(accuracy * 100, 2)\n",
    "    print(f\"Loss: {loss} Accuracy: {accuracy}\")\n",
    "evaluate_model(traffic_sign_model, test_images_resized, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d55e1c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Latency: 53.63 ms\n",
      "Min Latency: 31.0 ms\n",
      "Max Latency: 79.0 ms\n",
      "Standard Deviation: 9.39 ms\n",
      "Median Latency: 47.0 ms\n",
      "99th Percentile Latency: 78.0 ms\n",
      "90th Percentile Latency: 63.0 ms\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Latency Data\n",
    "def evaluate_latency(model, images, num_samples=500):\n",
    "    warmup_images = images[:10]\n",
    "    measurement_images = images[10:10 + num_samples]\n",
    "    for image in warmup_images:\n",
    "        _ = model.predict(np.expand_dims(image, axis=0), verbose=0)\n",
    "    time_records = []\n",
    "    for image in measurement_images:\n",
    "        sample = np.expand_dims(image, axis=0)\n",
    "        start_time = time.monotonic()\n",
    "        _ = model.predict(sample, verbose=0)\n",
    "        end_time = time.monotonic()\n",
    "        inference_time = (end_time - start_time) * 1000\n",
    "        time_records.append(inference_time)\n",
    "    return time_records\n",
    "latency_records = evaluate_latency(traffic_sign_model, test_images_resized)\n",
    "\n",
    "# Statistical Analysis of Latency\n",
    "print(f\"Average Latency: {np.round(np.mean(latency_records), 2)} ms\")\n",
    "print(f\"Min Latency: {np.round(np.min(latency_records), 2)} ms\")\n",
    "print(f\"Max Latency: {np.round(np.max(latency_records), 2)} ms\")\n",
    "print(f\"Standard Deviation: {np.round(np.std(latency_records), 2)} ms\")\n",
    "print(f\"Median Latency: {np.round(np.median(latency_records), 2)} ms\")\n",
    "print(f\"99th Percentile Latency: {np.round(np.percentile(latency_records, 99), 2)} ms\")\n",
    "print(f\"90th Percentile Latency: {np.round(np.percentile(latency_records, 90), 2)} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
